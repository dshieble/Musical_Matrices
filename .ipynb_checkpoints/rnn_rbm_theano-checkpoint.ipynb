{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danshiebler/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "# Author: Nicolas Boulanger-Lewandowski\n",
    "# University of Montreal (2012)\n",
    "# RNN-RBM deep learning tutorial\n",
    "# More information at http://deeplearning.net/tutorial/rnnrbm.html\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy\n",
    "try:\n",
    "    import pylab\n",
    "except ImportError:\n",
    "    print (\"pylab isn't available. If you use its functionality, it will crash.\")\n",
    "    print(\"It can be installed with 'pip install -q Pillow'\")\n",
    "\n",
    "from midi.utils import midiread, midiwrite\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.contrib import learn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "sys.path.append(\"music_rnn\")\n",
    "import pygame\n",
    "from matplotlib import pyplot as plt\n",
    "import midi_util\n",
    "import feature_encoder\n",
    "import music_lstm\n",
    "import time\n",
    "#RATHER THAN USE A HUGE DIRECT INTEGER ENCODING - TRY A DICTIONARY MAPPING\n",
    "\n",
    "\n",
    "#Don't use a python long as this don't work on 32 bits computers.\n",
    "numpy.random.seed(0xbeef)\n",
    "rng = RandomStreams(seed=numpy.random.randint(1 << 30))\n",
    "theano.config.warn.subtensor_merge_bug = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_rbm(v, W, bv, bh, k):\n",
    "    '''Construct a k-step Gibbs chain starting at v for an RBM.\n",
    "\n",
    "    v : Theano vector or matrix\n",
    "        If a matrix, multiple chains will be run in parallel (batch).\n",
    "    W : Theano matrix\n",
    "        Weight matrix of the RBM.\n",
    "    bv : Theano vector\n",
    "        Visible bias vector of the RBM.\n",
    "    bh : Theano vector\n",
    "        Hidden bias vector of the RBM.\n",
    "    k : scalar or Theano scalar\n",
    "        Length of the Gibbs chain.\n",
    "\n",
    "    Return a (v_sample, cost, monitor, updates) tuple:\n",
    "\n",
    "    v_sample : Theano vector or matrix with the same shape as `v`\n",
    "        Corresponds to the generated sample(s).\n",
    "    cost : Theano scalar\n",
    "        Expression whose gradient with respect to W, bv, bh is the CD-k\n",
    "        approximation to the log-likelihood of `v` (training example) under the\n",
    "        RBM. The cost is averaged in the batch case.\n",
    "    monitor: Theano scalar\n",
    "        Pseudo log-likelihood (also averaged in the batch case).\n",
    "    updates: dictionary of Theano variable -> Theano variable\n",
    "        The `updates` object returned by scan.\n",
    "    '''\n",
    "    def gibbs_step(v):\n",
    "        mean_h = T.nnet.sigmoid(T.dot(v, W) + bh)\n",
    "        h = rng.binomial(size=mean_h.shape, n=1, p=mean_h,\n",
    "                         dtype=theano.config.floatX)\n",
    "        mean_v = T.nnet.sigmoid(T.dot(h, W.T) + bv)\n",
    "        v = rng.binomial(size=mean_v.shape, n=1, p=mean_v,\n",
    "                         dtype=theano.config.floatX)\n",
    "        return mean_v, v\n",
    "\n",
    "\n",
    "    chain, updates = theano.scan(lambda v: gibbs_step(v)[1], outputs_info=[v], n_steps=k)\n",
    "\n",
    "    v_sample = chain[-1] #vsample is the final output of the gibbs chain - the sampled vector from the rbm\n",
    "\n",
    "    mean_v = gibbs_step(v_sample)[0]\n",
    "    monitor = T.xlogx.xlogy0(v, mean_v) + T.xlogx.xlogy0(1 - v, 1 - mean_v)\n",
    "    monitor = monitor.sum() / v.shape[0]\n",
    "\n",
    "    def free_energy(v):\n",
    "        return -(v * bv).sum() - T.log(1 + T.exp(T.dot(v, W) + bh)).sum()\n",
    "    #the cost is based on the difference in free energy between v and v_sample\n",
    "    cost = (free_energy(v) - free_energy(v_sample)) / v.shape[0]\n",
    "\n",
    "    return v_sample, cost, monitor, updates\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def shared_normal(num_rows, num_cols, scale=1):\n",
    "    '''Initialize a matrix shared variable with normally distributed\n",
    "    elements.'''\n",
    "    return theano.shared(numpy.random.normal(\n",
    "        scale=scale, size=(num_rows, num_cols)).astype(theano.config.floatX))\n",
    "\n",
    "\n",
    "def shared_zeros(*shape):\n",
    "    '''Initialize a vector shared variable with zero elements.'''\n",
    "    return theano.shared(numpy.zeros(shape, dtype=theano.config.floatX))\n",
    "\n",
    "\n",
    "def build_rnnrbm(n_visible, n_hidden, n_hidden_recurrent):\n",
    "    '''Construct a symbolic RNN-RBM and initialize parameters.\n",
    "\n",
    "    n_visible : integer\n",
    "        Number of visible units.\n",
    "    n_hidden : integer\n",
    "        Number of hidden units of the conditional RBMs.\n",
    "    n_hidden_recurrent : integer\n",
    "        Number of hidden units of the RNN.\n",
    "\n",
    "    Return a (v, v_sample, cost, monitor, params, updates_train, v_t,\n",
    "    updates_generate) tuple:\n",
    "\n",
    "    v : Theano matrix\n",
    "        Symbolic variable holding an input sequence (used during training)\n",
    "    v_sample : Theano matrix\n",
    "        Symbolic variable holding the negative particles for CD log-likelihood\n",
    "        gradient estimation (used during training)\n",
    "    cost : Theano scalar\n",
    "        Expression whose gradient (considering v_sample constant) corresponds\n",
    "        to the LL gradient of the RNN-RBM (used during training)\n",
    "    monitor : Theano scalar\n",
    "        Frame-level pseudo-likelihood (useful for monitoring during training)\n",
    "    params : tuple of Theano shared variables\n",
    "        The parameters of the model to be optimized during training.\n",
    "    updates_train : dictionary of Theano variable -> Theano variable\n",
    "        Update object that should be passed to theano.function when compiling\n",
    "        the training function.\n",
    "    v_t : Theano matrix\n",
    "        Symbolic variable holding a generated sequence (used during sampling)\n",
    "    updates_generate : dictionary of Theano variable -> Theano variable\n",
    "        Update object that should be passed to theano.function when compiling\n",
    "        the generation function.'''\n",
    "\n",
    "    W = shared_normal(n_visible, n_hidden, 0.01)\n",
    "    bv = shared_zeros(n_visible)\n",
    "    bh = shared_zeros(n_hidden)\n",
    "    Wuh = shared_normal(n_hidden_recurrent, n_hidden, 0.0001)\n",
    "    Wuv = shared_normal(n_hidden_recurrent, n_visible, 0.0001)\n",
    "    Wvu = shared_normal(n_visible, n_hidden_recurrent, 0.0001)\n",
    "    Wuu = shared_normal(n_hidden_recurrent, n_hidden_recurrent, 0.0001)\n",
    "    bu = shared_zeros(n_hidden_recurrent)\n",
    "\n",
    "    params = W, bv, bh, Wuh, Wuv, Wvu, Wuu, bu  # learned parameters as shared\n",
    "                                                # variables\n",
    "\n",
    "    v = T.matrix()  # a training sequence\n",
    "    u0 = T.zeros((n_hidden_recurrent,))  # initial value for the RNN hidden\n",
    "                                         # units\n",
    "\n",
    "    # If `v_t` is given, deterministic recurrence to compute the variable\n",
    "    # biases bv_t, bh_t at each time step. If `v_t` is None, same recurrence\n",
    "    # but with a separate Gibbs chain at each time step to sample (generate)\n",
    "    # from the RNN-RBM. The resulting sample v_t is returned in order to be\n",
    "    # passed down to the sequence history.\n",
    "    def recurrence(v_t, u_tm1):\n",
    "        bv_t = bv + T.dot(u_tm1, Wuv)\n",
    "        bh_t = bh + T.dot(u_tm1, Wuh)\n",
    "        generate = v_t is None\n",
    "        if generate:\n",
    "            print \"7777\"\n",
    "            v_t, _, _, updates = build_rbm(T.zeros((n_visible,)), W, bv_t,\n",
    "                                           bh_t, k=25)\n",
    "        u_t = T.tanh(bu + T.dot(v_t, Wvu) + T.dot(u_tm1, Wuu))\n",
    "        \n",
    "        return ([v_t, u_t], updates) if generate else [u_t, bv_t, bh_t]\n",
    "\n",
    "    # For training, the deterministic recurrence is used to compute all the\n",
    "    # {bv_t, bh_t, 1 <= t <= T} given v. Conditional RBMs can then be trained\n",
    "    # in batches using those parameters.\n",
    "    (u_t, bv_t, bh_t), updates_train = theano.scan(\n",
    "        lambda v_t, u_tm1, *_: recurrence(v_t, u_tm1),\n",
    "        sequences=v, outputs_info=[u0, None, None], non_sequences=params)\n",
    "\n",
    "    #Build this rbm based on the bias vectors that we already found \n",
    "    v_sample, cost, monitor, updates_rbm = build_rbm(v, W, bv_t[:], bh_t[:],\n",
    "                                                     k=15)\n",
    "    updates_train.update(updates_rbm)\n",
    "\n",
    "    # symbolic loop for sequence generation\n",
    "    (v_t, u_t), updates_generate = theano.scan(\n",
    "        lambda u_tm1, *_: recurrence(None, u_tm1),\n",
    "        outputs_info=[None, u0], non_sequences=params, n_steps=200)\n",
    "\n",
    "    return (v, v_sample, cost, monitor, params, updates_train, v_t,\n",
    "            updates_generate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class RnnRbm:\n",
    "    '''Simple class to train an RNN-RBM from MIDI files and to generate sample\n",
    "    sequences.'''\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_hidden=150,\n",
    "        n_hidden_recurrent=100,\n",
    "        lr=0.001,\n",
    "        r=(21, 109),\n",
    "        dt=0.3\n",
    "    ):\n",
    "        '''Constructs and compiles Theano functions for training and sequence\n",
    "        generation.\n",
    "\n",
    "        n_hidden : integer\n",
    "            Number of hidden units of the conditional RBMs.\n",
    "        n_hidden_recurrent : integer\n",
    "            Number of hidden units of the RNN.\n",
    "        lr : float\n",
    "            Learning rate\n",
    "        r : (integer, integer) tuple\n",
    "            Specifies the pitch range of the piano-roll in MIDI note numbers,\n",
    "            including r[0] but not r[1], such that r[1]-r[0] is the number of\n",
    "            visible units of the RBM at a given time step. The default (21,\n",
    "            109) corresponds to the full range of piano (88 notes).\n",
    "        dt : float\n",
    "            Sampling period when converting the MIDI files into piano-rolls, or\n",
    "            equivalently the time difference between consecutive time steps.'''\n",
    "\n",
    "        self.r = r\n",
    "        self.dt = dt\n",
    "        (v, v_sample, cost, monitor, params, updates_train, v_t,\n",
    "            updates_generate) = build_rnnrbm(\n",
    "                r[1] - r[0],\n",
    "                n_hidden,\n",
    "                n_hidden_recurrent\n",
    "            )\n",
    "\n",
    "        gradient = T.grad(cost, params, consider_constant=[v_sample])\n",
    "        updates_train.update(\n",
    "            ((p, p - lr * g) for p, g in zip(params, gradient))\n",
    "        )\n",
    "        self.train_function = theano.function(\n",
    "            [v],\n",
    "            monitor,\n",
    "            updates=updates_train\n",
    "        )\n",
    "        self.generate_function = theano.function(\n",
    "            [],\n",
    "            v_t,\n",
    "            updates=updates_generate\n",
    "        )\n",
    "\n",
    "    def train(self, files, batch_size=100, num_epochs=200):\n",
    "        '''Train the RNN-RBM via stochastic gradient descent (SGD) using MIDI\n",
    "        files converted to piano-rolls.\n",
    "\n",
    "        files : list of strings\n",
    "            List of MIDI files that will be loaded as piano-rolls for training.\n",
    "        batch_size : integer\n",
    "            Training sequences will be split into subsequences of at most this\n",
    "            size before applying the SGD updates.\n",
    "        num_epochs : integer\n",
    "            Number of epochs (pass over the training set) performed. The user\n",
    "            can safely interrupt training with Ctrl+C at any time.'''\n",
    "\n",
    "        assert len(files) > 0, 'Training set is empty!' \\\n",
    "                               ' (did you download the data files?)'\n",
    "        dataset = [midiread(f, self.r,\n",
    "                            self.dt).piano_roll.astype(theano.config.floatX)\n",
    "                   for f in tqdm(files[:3])]\n",
    "\n",
    "        try:\n",
    "            for epoch in range(num_epochs):\n",
    "                numpy.random.shuffle(dataset)\n",
    "                costs = []\n",
    "\n",
    "                for s, sequence in tqdm(enumerate(dataset)):\n",
    "                    for i in range(0, len(sequence), batch_size):\n",
    "                        cost = self.train_function(sequence[i:i + batch_size])\n",
    "                        costs.append(cost)\n",
    "\n",
    "                print('Epoch %i/%i' % (epoch + 1, num_epochs))\n",
    "                print(numpy.mean(costs))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print('Interrupted by user.')\n",
    "\n",
    "    def generate(self, filename, show=True):\n",
    "        '''Generate a sample sequence, plot the resulting piano-roll and save\n",
    "        it as a MIDI file.\n",
    "\n",
    "        filename : string\n",
    "            A MIDI file will be created at this location.\n",
    "        show : boolean\n",
    "            If True, a piano-roll of the generated sequence will be shown.'''\n",
    "\n",
    "        piano_roll = self.generate_function()\n",
    "        midiwrite(filename, piano_roll, self.r, self.dt)\n",
    "        if show:\n",
    "            extent = (0, self.dt * len(piano_roll)) + self.r\n",
    "            pylab.figure()\n",
    "            pylab.imshow(piano_roll.T, origin='lower', aspect='auto',\n",
    "                         interpolation='nearest', cmap=pylab.cm.gray_r,\n",
    "                         extent=extent)\n",
    "            pylab.xlabel('time (s)')\n",
    "            pylab.ylabel('MIDI note number')\n",
    "            pylab.title('generated piano-roll')\n",
    "\n",
    "\n",
    "def test_rnnrbm(batch_size=100, num_epochs=5):\n",
    "    model = RnnRbm()\n",
    "    re = 'data/Nottingham/train/*.mid'\n",
    "    model.train(glob.glob(re),\n",
    "                batch_size=batch_size, num_epochs=num_epochs)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtensor{::}.0\n",
      "Elemwise{add,no_inplace}.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 125.48it/s]\n",
      "3it [00:00, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "-59.1046329191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:00, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "-54.753071717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:00, 12.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "-51.346195151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:00, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "-48.2554469425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:00, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "-45.7761268449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = test_rnnrbm()\n",
    "# model.generate('sample1.mid')\n",
    "# model.generate('sample2.mid')\n",
    "# pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def dump_midi(midi_vec, filename, time_step=32, resolution=480, n=128):\n",
    "    M  = midi_util.MidiWriter()\n",
    "    M.dump_sequence_to_midi(midi_vec, filename, time_step, resolution)\n",
    "\n",
    "def plot_midi(midi_vec, n=128):\n",
    "    plt.imshow(midi_vec, extent=[0, 1, 0, 1])\n",
    "\n",
    "    \n",
    "re = 'data/music_all/train/*.mid'\n",
    "files = glob.glob(re)\n",
    "f = files[0]\n",
    "r=(21, 109)\n",
    "dt=0.3\n",
    "m = midiread(f, r, dt).piano_roll\n",
    "plot_midi(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
